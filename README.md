# FineTune-DistilBERT-Sentiment
This project fine-tunes DistilBERT for sentiment analysis using LoRA and BitsAndBytes quantization. It leverages peft for efficient fine-tuning, trains a spam classifier on text data, and optimizes performance with quantized layers. The model predicts whether a message is spam or ham.
